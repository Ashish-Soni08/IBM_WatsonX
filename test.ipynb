{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import random\n",
    "from typing import Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "from datasets import Dataset, load_dataset\n",
    "from llama_index.packs.raft_dataset import RAFTDatasetPack\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dotenv_values(\"./backend/.env\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = openai.OpenAI(\n",
    "    api_key=config[\"OPENAI_API_KEY\"],\n",
    "    organization=config[\"ORGANIZATION_ID\"],\n",
    "    project=config[\"PROJECT_ID\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "LLM = OpenAI(model=\"gpt-4o-2024-05-13\", api_key=config[\"OPENAI_API_KEY\"])\n",
    "\n",
    "EMBED_MODEL = OpenAIEmbedding(model=\"text-embedding-3-small\", api_key=config[\"OPENAI_API_KEY\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with a sample pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_raft_dataset = RAFTDatasetPack(file_path=\"./data/sample.pdf\",\n",
    "                                      llm=LLM,\n",
    "                                      embed_model=EMBED_MODEL,\n",
    "                                      num_questions_per_chunk=5,\n",
    "                                      num_distract_docs=3,\n",
    "                                      chunk_size=400\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dataset = sample_raft_dataset.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"./data/sample_pdf_dataset/sample\"\n",
    "\n",
    "sample_dataset.to_json(output_path + \".jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "from ibm_watsonx_ai.foundation_models import ModelInference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ibm_watsonx_ai.client:Client successfully initialized\n",
      "INFO:ibm_watsonx_ai.wml_resource:Successfully finished Get available foundation models for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/foundation_model_specs?version=2024-09-09&project_id=1ebac0e0-ee31-4a71-a95d-78bf576b69eb&filters=function_text_generation%2C%21lifecycle_withdrawn%3Aand&limit=200'\n"
     ]
    }
   ],
   "source": [
    "model_inference = ModelInference(\n",
    "    model_id=config[\"WATSONX_MODEL_ID\"],\n",
    "    credentials={\n",
    "        \"apikey\": config[\"IBM_CLOUD_API_KEY\"],\n",
    "        \"url\": config[\"IBM_CLOUD_URL\"]\n",
    "    },\n",
    "    project_id=config[\"WATSONX_PROJECT_ID\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2024-09-09 \"HTTP/1.1 200 OK\"\n",
      "INFO:ibm_watsonx_ai.wml_resource:Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2024-09-09'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" I'm doing well, thank you for asking. I've been working on a project lately, and\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inference.generate_text(\"Hello, how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_params = {\n",
    "    \"decoding_method\": \"sample\",\n",
    "    \"min_new_tokens\": 1,\n",
    "    \"top_k\": 50,\n",
    "    \"top_p\": 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ibm_watsonx_ai.client:Client successfully initialized\n",
      "INFO:ibm_watsonx_ai.wml_resource:Successfully finished Get available foundation models for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/foundation_model_specs?version=2024-09-09&project_id=1ebac0e0-ee31-4a71-a95d-78bf576b69eb&filters=function_text_generation%2C%21lifecycle_withdrawn%3Aand&limit=200'\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.ibm import WatsonxLLM\n",
    "\n",
    "watsonx_llm = WatsonxLLM(\n",
    "    model_id=config[\"WATSONX_MODEL_ID\"],\n",
    "    url=config[\"IBM_CLOUD_URL\"],\n",
    "    apikey=config[\"IBM_CLOUD_API_KEY\"],\n",
    "    project_id=config[\"WATSONX_PROJECT_ID\"],\n",
    "    temperature=0.2,\n",
    "    max_new_tokens=300,\n",
    "    additional_params=additional_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2024-09-09 \"HTTP/1.1 200 OK\"\n",
      "INFO:ibm_watsonx_ai.wml_resource:Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2024-09-09'\n"
     ]
    }
   ],
   "source": [
    "response = watsonx_llm.complete(\"Hello, how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_id': 'ibm/granite-13b-chat-v2', 'model_version': '2.1.0', 'created_at': '2024-09-19T20:01:59.069Z', 'results': [{'generated_text': \"\\n\\nA: I'm doing well, thank you. And you?\\n\\nB: I'm good, thank you. It's a beautiful day today.\\n\\nA: I agree, it's a great day for a walk in the park.\\n\\nB: That sounds like a wonderful idea. I'd love to go. Do you want to join me?\\n\\nA: I'd love to! It's been a while since we last walked together.\\n\\nB: Me too. I've been meaning to catch up with you.\\n\\nA: I've been busy with work lately, but I'm making an effort to take some time for myself and do things I enjoy.\\n\\nB: That's great to hear. I'm sure it's good for your mental health.\\n\\nA: Absolutely. I've been feeling a bit overwhelmed lately, and I think a walk in the park will help me relax and rejuvenate.\\n\\nB: I'm sure it will. I'm looking forward to it.\\n\\nA: Great. Let's meet at the park entrance at 2 pm.\\n\\nB: Sure thing. See you then!\\n\\nA: Thank you.\\n\\nIn this dialogue, the speaker and the listener are planning to go for a walk in the park together. The speaker expresses her desire to take a break from work and enjoy some time in nature, while the listener agrees and offers to accompany her\", 'generated_token_count': 300, 'input_token_count': 6, 'stop_reason': 'max_tokens', 'seed': 3149956786}]}\n"
     ]
    }
   ],
   "source": [
    "print(response.raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PowerBI DAX PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use any llama-hub loader to get documents!\n",
    "dax_raft_dataset = RAFTDatasetPack(file_path=\"./data/DAX/14_power-bi-dax.pdf\",\n",
    "                                      llm=LLM,\n",
    "                                      embed_model=EMBED_MODEL,\n",
    "                                      num_questions_per_chunk=5,\n",
    "                                      num_distract_docs=3,\n",
    "                                      chunk_size=1024\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dax_dataset = dax_raft_dataset.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"./data/dax_pdf_dataset/dax\"\n",
    "\n",
    "dax_dataset.to_json(output_path + \".jsonl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".powerbi-ai-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
